{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Open Google Cloud SDK Shell and enter the following code:\n",
    "\n",
    "`set GOOGLE_APPLICATION_CREDENTIALS = .\\methods\\translation\\apikey.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages & Define Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import translate_v2 as translate\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Define rootpath\n",
    "rp = '.'\n",
    "mp = 'methods\\\\'\n",
    "dp = 'data\\\\tweet_data\\\\'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text,target='en'):\n",
    "    \"\"\"\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    https://cloud.google.com/translate/docs/languages\n",
    "    \"\"\"\n",
    "    translate_client = translate.Client()\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Spanish Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spanish tweets\n",
    "spain_tweets = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_VADER.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set inputs\n",
    "df     = spain_tweets\n",
    "n      = 10\n",
    "st_row = 1000\n",
    "loops  = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group_index to split df by\n",
    "df['group_index'] = pd.Series(df.index.values).apply(lambda x: x // n)\n",
    "\n",
    "# Use group_index to split df into list of smaller dataframes\n",
    "split_df = list(df.groupby('group_index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to populate with transalated tweet dfs\n",
    "trans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9990:10000 of 122707 tweets called --- Loop Run Time (s): 24.948\r"
     ]
    }
   ],
   "source": [
    "# if statement which checks whether planned loop will exceed total rows in the dataframe and adjusts values if it will\n",
    "if (st_row//n)+loops < len(split_df): # if planned iterations do not exceed list length\n",
    "    st_loop = st_row//n ; en_loop = (st_row//n)+loops ; en_row = st_row+n*loops # define start/end loops/rows\n",
    "else: # if planned iterations do exceed list length\n",
    "    st_loop = st_row//n ; en_loop = len(split_df) ; en_row = df.shape[0] ; loops = en_loop - st_loop # redefine start/end loops/rows to ensure df is not exceeded\n",
    "    \n",
    "# for loop which translates tweets, adds them to trans then saves them as a dataframe\n",
    "for group in split_df[st_loop:en_loop]:\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Translate tweets\n",
    "    group[1]['translated_text'] = group[1]['VADER_text'].apply(lambda x: translate_text(x)['translatedText'] )\n",
    "    \n",
    "    # Delete group_index variable (used for splitting variables, so no longer needed)\n",
    "    del group[1]['group_index']\n",
    "    \n",
    "    # Append to trans\n",
    "    trans.append(group[1])\n",
    "    \n",
    "    # Concatenate all tweets translated so far into a dataframe\n",
    "    trans_df = pd.concat(trans)\n",
    "    \n",
    "    # Save as csv\n",
    "    trans_df.to_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_' + str(st_row) + '_' + str(en_row) + '.csv')\n",
    "    \n",
    "    # Print progress\n",
    "    loop = group[0] - st_row//n #  Define loop iteration\n",
    "    en_loop_row = st_row+loop*n+n if st_row+loop*n+n <= df.shape[0] else df.shape[0] # Check whether loop exceeds df index and adjust if it does\n",
    "    print(str(st_row+loop*n) + ':' + str(en_loop_row) + ' of ' + str(df.shape[0]) + ' tweets called', end=\" --- \")\n",
    "    \n",
    "    # Print run-time\n",
    "    print(\"Loop Run Time (s): %s\" % round((time.time() - start_time),3), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all translated tweets\n",
    "grman_tweets_0_10000       = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_0_10000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_10000_20000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_10000_20000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_20000_30000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_20000_30000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_30000_40000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_30000_40000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_40000_50000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_40000_50000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_50000_60000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_50000_60000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_60000_70000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_60000_70000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_70000_80000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_70000_80000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_80000_90000   = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_80000_90000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_90000_100000  = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_90000_100000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_100000_110000 = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_100000_110000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "grman_tweets_110000_117408 = pd.read_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_translations_110000_117408.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Combine into single dataframe\n",
    "grman_tweets = pd.concat([grman_tweets_0_10000, grman_tweets_10000_20000, grman_tweets_20000_30000, grman_tweets_30000_40000,\n",
    "                         grman_tweets_40000_50000, grman_tweets_50000_60000, grman_tweets_60000_70000, grman_tweets_70000_80000,\n",
    "                         grman_tweets_80000_90000, grman_tweets_90000_100000, grman_tweets_100000_110000, grman_tweets_110000_117408]).reset_index(drop=True)\n",
    "\n",
    "# Save tweets\n",
    "#grman_tweets.to_csv(rp + dp + 'tweets\\\\grman_tweets_01122019_01052020_VADER_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all translated tweets\n",
    "italy_tweets_0_10000       = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_0_10000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_10000_20000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_10000_20000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_20000_30000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_20000_30000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_30000_40000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_30000_40000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_40000_50000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_40000_50000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_50000_60000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_50000_60000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_60000_70000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_60000_70000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_70000_80000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_70000_80000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_80000_90000   = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_80000_90000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_90000_100000  = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_90000_100000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "italy_tweets_100000_104066 = pd.read_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_translations_100000_104066.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Combine into single dataframe\n",
    "italy_tweets = pd.concat([italy_tweets_0_10000, italy_tweets_10000_20000, italy_tweets_20000_30000, italy_tweets_30000_40000, italy_tweets_40000_50000,\n",
    "                          italy_tweets_50000_60000, italy_tweets_60000_70000, italy_tweets_70000_80000, italy_tweets_80000_90000, italy_tweets_90000_100000,\n",
    "                          italy_tweets_100000_104066]).reset_index(drop=True)\n",
    "\n",
    "# Save tweets\n",
    "italy_tweets.to_csv(rp + dp + 'tweets\\\\italy_tweets_01122019_01052020_VADER_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all translated tweets\n",
    "spain_tweets_0_1000        = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_0_1000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_1000_10000    = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_1000_10000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_10000_20000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_10000_20000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_20000_30000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_20000_30000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_30000_31000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_30000_31000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_31000_40000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_31000_40000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_40000_50000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_40000_50000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_50000_60000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_50000_60000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_60000_61000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_60000_61000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_61000_70000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_61000_70000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_70000_80000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_70000_80000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_80000_90000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_80000_90000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_90000_91000   = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_90000_91000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_91000_100000  = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_91000_100000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_100000_110000 = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_100000_110000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_110000_120000 = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_110000_120000.csv').drop(['Unnamed: 0'], axis=1)\n",
    "spain_tweets_120000_122707 = pd.read_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_translations_120000_122707.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# Combine into single dataframe\n",
    "spain_tweets = pd.concat([spain_tweets_0_1000, spain_tweets_1000_10000, spain_tweets_10000_20000, spain_tweets_20000_30000, spain_tweets_30000_31000, spain_tweets_31000_40000, \n",
    "                          spain_tweets_40000_50000, spain_tweets_50000_60000, spain_tweets_60000_61000, spain_tweets_61000_70000, spain_tweets_70000_80000, spain_tweets_80000_90000, \n",
    "                          spain_tweets_90000_91000, spain_tweets_91000_100000, spain_tweets_100000_110000, spain_tweets_110000_120000, spain_tweets_120000_122707]).reset_index(drop=True)\n",
    "\n",
    "# Save tweets\n",
    "spain_tweets.to_csv(rp + dp + 'tweets\\\\spain_tweets_01122019_01052020_VADER_translated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
